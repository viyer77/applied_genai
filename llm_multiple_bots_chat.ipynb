{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122521a8",
   "metadata": {},
   "source": [
    "## Multiple bots chatting with each other\n",
    "\n",
    "\n",
    "\n",
    "Week2 Day 1 exercise (LLM Engineer course on Udemy by Ed Donner)\n",
    "\n",
    "Reference: https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2049d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "grok_api_key = os.getenv(\"GROK_API_KEY\")\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")\n",
    "\n",
    "if grok_api_key:\n",
    "    print(f\"Grok API Key exists and begins {grok_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Grok API Key not set (and this is optional)\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00acfb10",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI client library\n",
    "# A thin wrapper around calls to HTTP endpoints\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "# For Gemini, DeepSeek and Groq, we can use the OpenAI python client\n",
    "# Because Google and DeepSeek have endpoints compatible with OpenAI\n",
    "# And OpenAI allows you to change the base_url\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "deepseek_url = \"https://api.deepseek.com\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "grok_url = \"https://api.x.ai/v1\"\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=deepseek_url)\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "grok = OpenAI(api_key=grok_api_key, base_url=grok_url)\n",
    "openrouter = OpenAI(base_url=openrouter_url, api_key=openrouter_api_key)\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_names = [\"Alex\", \"Blake\", \"Charlie\"]\n",
    "\n",
    "\n",
    "bot_models = {\"Alex\": \"llama3.2\", \"Blake\": \"llama3.2\", \"Charlie\": \"llama3.2\"}\n",
    "\n",
    "bot_system_prompts = {\n",
    "    \"Alex\": \"\"\"\n",
    "You are Alex, a snarky an confrontational chat bot, you challenge and confront anything said by others,\n",
    "you are in conversation with Blake and Charlie, respond accordingly\n",
    "\"\"\",\n",
    "    \"Blake\": \"\"\"\n",
    "You are Blake, a jovial chat bot, crack jokes and dont take anything seriously,\n",
    "you are in conversation with Alex and Charlie, respond accordingly\n",
    "\"\"\",\n",
    "    \"Charlie\": \"\"\"\n",
    "You are Charlie, a polite and formal chat bot, always try to get along with everyone,\n",
    "you are in conversation with Alex and Blake, respond accordingly\n",
    "\"\"\",\n",
    "}\n",
    "\n",
    "conversation = f\"\"\"\n",
    "Alex: Hi\n",
    "Blake: Hola, what a funny day!\n",
    "Charlie: Hi there\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_user_prompt(bot_name):\n",
    "    return f\"\"\"\n",
    "    You are {bot_name} in conversation with other bots,\n",
    "    Here is the conversation so far, each line starts with the name of the bot followed by :\n",
    "    For example: if Alex says something, it will be like this:\n",
    "    Alex: <message>\n",
    "    If Blake says something, it will be like this:\n",
    "    Blake: <message>\n",
    "    If Charlie says something, it will be like this:\n",
    "    Charlie: <message>\n",
    "    When you respond, follow the format of the conversation so far, and respond accordingly\n",
    "    {conversation}\n",
    "    Now with this, respond accordingly\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_messages(bot_name):\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": bot_system_prompts[bot_name]},\n",
    "        {\"role\": \"user\", \"content\": get_user_prompt(bot_name)},\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_response(bot_name):\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=bot_models[bot_name], messages=get_messages(bot_name)\n",
    "    )\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    return response.choices[0].message.content + \"\\n\"\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    for bot_name in bot_names:\n",
    "        conversation += get_response(bot_name)\n",
    "        print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b406bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eng_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
